{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter tuning by Aditya\n"
      ],
      "metadata": {
        "id": "gx5QFn4lDGW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Introduction to Hyperparameter Tuning\n",
        "\n",
        "### 1.1 Understanding Hyperparameters\n",
        "Hyperparameters are external configuration settings for a model that cannot be learned from the data. These include learning rates, batch sizes, and regularization strengths.\n",
        "\n",
        "### 1.2 Importance of Hyperparameter Tuning\n",
        "Optimal hyperparameter values significantly impact a model's performance. Hyperparameter tuning aims to find the best combination for improved accuracy and generalization.\n",
        "\n",
        "##What are batch sizes ?\n",
        "\n",
        "Batch size is a hyperparameter that specifies the number of data samples utilized in one iteration (or training step) to update the model's weights. It is an important concept in the training of neural networks and other machine learning models.\n",
        "\n",
        "*   **Batch:** A set of data samples processed together in one iteration. The model weights are updated after processing each batch.\n",
        "*   **Batch Size:** The number of data samples in a batch. It is a hyperparameter that can be adjusted based on computational resources, model architecture, and the size of the training dataset.\n",
        "*   Typical batch sizes are powers of 2, such as 32, 64, 128, etc. The choice of batch size can also depend on the nature of the data. For example, in tasks where data points are correlated or sequential (like in time series), a smaller batch size is often preferred.\n",
        "\n",
        "## What are regularization strengths ?\n",
        "\n",
        "Regularization is a technique used to prevent overfitting in machine learning models. Regularization strength, often denoted by a hyperparameter, controls the amount of regularization applied to the model during training. It influences the impact of regularization penalties on the loss function, helping to balance between fitting the training data well and avoiding overfitting.\n",
        "\n",
        "- Two common types of regularization are L1 regularization (Lasso) and L2 regularization (Ridge). The regularization strength, usually denoted as \"alpha\" or \"lambda,\" determines the magnitude of the regularization term added to the loss function.\n",
        "\n",
        "- Hyperparameter tuning techniques, such as grid search or randomized search, are often employed to find the best regularization strength for a given problem.\n",
        "\n",
        "\n",
        "## Must not forget the estimators\n",
        "\n",
        "Estimators are a fundamental concept in the scikit-learn library for machine learning in Python. In scikit-learn, an estimator is any object that learns from data and can be used for predictions. Examples include classifiers, regressors, and clustering algorithms. Each type of estimator in scikit-learn exposes a _fit_ method to train the model and a _predict_ method to make predictions.\n",
        "\n",
        "- Hyperparameters are external configurations for an estimator that cannot be learned from the training data. They affect the model's learning process and its ability to generalize to new data.\n",
        "\n",
        "- Identifying the optimal values for hyperparameters is crucial for achieving the best performance of an estimator. The process of hyperparameter tuning involves systematically searching through different hyperparameter combinations to find the ones that result in the best model.\n",
        "\n",
        "- Common techniques include grid search, random search, and more advanced methods like Bayesian optimization.\n",
        "\n",
        "## In deep learning we also have few different types of hyper parameters\n",
        "\n",
        "- Epoch size\n",
        "- Dropout rate (Fraction of randomly selected neurons to be ignored during training)\n",
        "- Activation functions\n",
        "- Weight initialization (We have different methods for choosing how we gonna initialize the weights)\n",
        "- Optimizer\n",
        "- Learning rate scheduler\n",
        "- Kernel size\n",
        "- Strides\n",
        "\n",
        "## Kernel size\n",
        "\n",
        "In CNNs, a kernel (or filter) is a small matrix applied to an input image to extract features. The kernel size refers to the dimensions of this matrix.\n",
        "\n",
        "- For example, a kernel size of (3,3) implies a 3x3 matrix. During convolution, the kernel slides over the input image in both dimensions, and at each position, it performs an element-wise multiplication and sums up the results to produce a feature map.\n",
        "\n",
        "- **Strides :-** defines the step size at which the kernel moves across the input image during convolution.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UuIJKCNcDadt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning about different tools for hypertuning"
      ],
      "metadata": {
        "id": "jG2x6VbWPzxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid Search\n",
        "\n",
        "Grid search is a hyperparameter tuning technique used in machine learning to systematically search through a predefined set of hyperparameter values for a given model. The goal is to find the combination of hyperparameter values that results in the best model performance.\n",
        "\n",
        "Here's a detailed explanation of grid search and its parameters:\n",
        "\n",
        "1. **Hyperparameters:**\n",
        "   - Hyperparameters are parameters that are not learned from the data but are set prior to the training process.\n",
        "   - Examples include learning rate, regularization strength, the number of hidden layers, and the number of nodes in each layer for neural networks.\n",
        "\n",
        "2. **Grid Search:**\n",
        "   - Grid search involves defining a grid of hyperparameter values to explore.\n",
        "   - For each combination of hyperparameters in the grid, a model is trained and evaluated.\n",
        "   - The combination that produces the best performance is selected as the optimal set of hyperparameters.\n",
        "\n",
        "3. **Parameters of Grid Search:**\n",
        "   - **Param_grid:** This is the dictionary or list of dictionaries that defines the hyperparameter grid to be searched. Each key in the dictionary corresponds to a hyperparameter, and the values are lists of possible values for that hyperparameter.\n",
        "\n",
        "   - **Scoring:** This parameter defines the metric used to evaluate the performance of the model for each combination of hyperparameters. Common metrics include accuracy, precision, recall, F1 score, and more.\n",
        "\n",
        "   - **CV (Cross-validation):** Grid search often employs cross-validation to assess the model's performance more reliably. The CV parameter determines the number of folds used in cross-validation.\n",
        "\n",
        "   - **Refit:** This parameter, when set to True, refits the best model with the entire dataset after finding the optimal hyperparameters.\n",
        "\n",
        "   - **Verbose:** Determines the amount of output information during the grid search. Higher values provide more details.\n",
        "\n",
        "   - **n_jobs:** Specifies the number of parallel jobs to run during the grid search. Setting it to -1 uses all available processors.\n"
      ],
      "metadata": {
        "id": "F9kCn3RdP4nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, scoring='accuracy', cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "accuracy = best_model.score(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L8dlSzvQFc1",
        "outputId": "d12993a2-1cc0-4f54-de56-d8ebb6c6a502"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random search\n",
        "\n",
        "Random search is another hyperparameter tuning technique, similar to grid search, used to find the optimal combination of hyperparameters for a machine learning model. Instead of searching through a predefined grid of hyperparameter values, random search samples hyperparameter values randomly from specified distributions. This approach can be more efficient than grid search when the search space is large.\n",
        "\n",
        "\n",
        "\n",
        "*   Random search involves defining a range or distribution for each hyperparameter.\n",
        "*   For each iteration, random values are sampled from these distributions for each hyperparameter.\n",
        "*   The model is trained and evaluated with these random hyperparameter values.\n",
        "*   The process is repeated for a specified number of iterations or until computational resources are exhausted.\n",
        "*   The combination that produces the best performance is selected as the optimal set of hyperparameters.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kwDBkNj-aq6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define the hyperparameter distributions\n",
        "param_distributions = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': randint(2, 10),\n",
        "    'min_samples_leaf': randint(1, 4)\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# Perform random search with cross-validation\n",
        "random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_distributions,\n",
        "                                   n_iter=10, scoring='accuracy', cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "best_model = random_search.best_estimator_\n",
        "accuracy = best_model.score(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN2xrOZaQLqa",
        "outputId": "90efe509-db1d-4f56-e883-745e5379a8bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 20, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 137}\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Optimization\n",
        "\n",
        "Bayesian Optimization is a probabilistic model-based optimization technique used for finding the global optimum of an objective function in a noisy or expensive-to-evaluate search space. It models the objective function as a probability distribution and uses the information gained from each evaluation to update this distribution, guiding the search toward promising regions.\n",
        "\n",
        "Here's a detailed explanation of Bayesian Optimization and its parameters:\n",
        "\n",
        "1. **Objective Function:**\n",
        "   - The function we want to optimize, often referred to as the objective function or the fitness function.\n",
        "\n",
        "2. **Surrogate Model:**\n",
        "   - Bayesian Optimization maintains a probabilistic surrogate model that approximates the true objective function. Gaussian processes (GP) are commonly used as surrogate models due to their ability to model uncertainty.\n",
        "\n",
        "3. **Acquisition Function:**\n",
        "   - The acquisition function is a criterion that guides the search for the next point to evaluate. It balances exploration (sampling in unexplored regions) and exploitation (sampling in regions where the objective function is likely to be optimal).\n",
        "\n",
        "4. **Parameters of Bayesian Optimization:**\n",
        "   - **Bounds:** Specifies the search space constraints for each hyperparameter. For each dimension, you define the lower and upper bounds.\n",
        "\n",
        "   - **Objective Function:** The actual function to be optimized.\n",
        "\n",
        "   - **Surrogate Model (Kernel, GP Parameters):** The choice of the surrogate model, along with its hyperparameters, affects how well the model captures the true objective function.\n",
        "\n",
        "   - **Acquisition Function (e.g., Expected Improvement, Probability of Improvement):** The acquisition function determines how the surrogate model guides the search. Different acquisition functions have different characteristics.\n",
        "\n",
        "   - **Initial Design:** A set of initial points where the objective function is evaluated. These points help in building the initial surrogate model.\n",
        "\n",
        "   - **Exploration-Exploitation Trade-off:** Parameters that control the balance between exploration and exploitation. For example, in Expected Improvement, you might have a parameter to control the trade-off.\n",
        "\n",
        "   - **Number of Iterations (or Evaluations):** Specifies the total number of iterations or evaluations of the objective function.\n",
        "\n",
        "   - **Noise Model:** Bayesian Optimization can handle noisy evaluations. The noise model, if known, can be incorporated into the optimization process.\n",
        "\n",
        "   - **Parallelism:** Specifies the number of parallel evaluations of the objective function that can be performed simultaneously."
      ],
      "metadata": {
        "id": "4u8777x0b2AN"
      }
    }
  ]
}