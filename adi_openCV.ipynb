{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# OpenCV tutorials by Aditya"
      ],
      "metadata": {
        "id": "tNySXeXV9uiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 1. Image Reading and Preprocessing in OpenCV\n",
        "\n",
        "**Image Reading:**\n",
        "In OpenCV, you can use the `cv2.imread()` function to read images. For example:\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "```\n",
        "\n",
        "**Image Preprocessing:**\n",
        "Preprocessing is essential for various computer vision tasks. Common preprocessing steps include resizing, converting to grayscale, and normalization.\n",
        "\n",
        "```python\n",
        "# Resize the image\n",
        "resized_image = cv2.resize(image, (new_width, new_height))\n",
        "\n",
        "# Convert to grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Normalize the pixel values\n",
        "normalized_image = cv2.normalize(gray_image, None, 0, 255, cv2.NORM_MINMAX)\n",
        "```\n",
        "\n",
        "### 2. Image Thresholding Techniques\n",
        "\n",
        "**Thresholding:**\n",
        "Thresholding is used to segment images based on pixel intensity. OpenCV provides various thresholding methods, including simple thresholding, adaptive thresholding, and Otsu's thresholding.\n",
        "\n",
        "```python\n",
        "# Simple Thresholding\n",
        "ret, binary_image = cv2.threshold(gray_image, threshold_value, max_value, cv2.THRESH_BINARY)\n",
        "\n",
        "# Adaptive Thresholding\n",
        "adaptive_image = cv2.adaptiveThreshold(gray_image, max_value, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, C)\n",
        "```\n",
        "\n",
        "### 3. Contour Detection and Hierarchy\n",
        "\n",
        "**Contour Detection:**\n",
        "Contours are the boundaries of objects in an image. OpenCV provides `cv2.findContours()` for contour detection.\n",
        "\n",
        "```python\n",
        "contours, hierarchy = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "```\n",
        "\n",
        "**Hierarchy:**\n",
        "Hierarchy in contours describes the relationships between contours, such as nested contours.\n",
        "\n",
        "```python\n",
        "# Example: Drawing contours with hierarchy\n",
        "contour_image = image.copy()\n",
        "cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
        "```\n",
        "\n",
        "### 4. Counting and Tracking Objects in Images\n",
        "\n",
        "**Counting Objects:**\n",
        "Counting objects involves analyzing the number of contours detected.\n",
        "\n",
        "```python\n",
        "object_count = len(contours)\n",
        "print(f'Total objects: {object_count}')\n",
        "```\n",
        "\n",
        "**Tracking Objects:**\n",
        "For object tracking, you might use additional techniques like centroid tracking.\n",
        "\n",
        "```python\n",
        "# Example: Centroid tracking\n",
        "for contour in contours:\n",
        "    M = cv2.moments(contour)\n",
        "    centroid_x = int(M['m10'] / M['m00'])\n",
        "    centroid_y = int(M['m01'] / M['m00'])\n",
        "    # Use centroid for tracking or other tasks\n",
        "```"
      ],
      "metadata": {
        "id": "Jzk-syeM9yrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling real-world challenges in image processing involves addressing issues that may arise due to various factors, such as noise, occlusion, lighting conditions, and variations in object appearance. Here are some strategies for addressing these challenges using OpenCV:\n",
        "\n",
        "### 1. Dealing with Noise:\n",
        "\n",
        "**Problem:** Images from real-world scenarios often contain noise, which can be random variations in pixel values.\n",
        "\n",
        "**Solution:** Apply image smoothing or blurring techniques to reduce noise.\n",
        "\n",
        "```python\n",
        "# Example: Applying Gaussian Blur to handle noise\n",
        "blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "```\n",
        "\n",
        "**Additional Techniques:** Other techniques like median blur or bilateral filter can also be used depending on the type of noise.\n",
        "\n",
        "```python\n",
        "# Median Blur\n",
        "median_blurred = cv2.medianBlur(image, 5)\n",
        "\n",
        "# Bilateral Filter\n",
        "bilateral_filtered = cv2.bilateralFilter(image, 9, 75, 75)\n",
        "```\n",
        "\n",
        "### 2. Handling Occlusion:\n",
        "\n",
        "**Problem:** Occlusion occurs when objects are partially or fully hidden by other objects.\n",
        "\n",
        "**Solution:** Utilize more sophisticated object tracking or segmentation techniques.\n",
        "\n",
        "```python\n",
        "# Example: Object tracking with OpenCV trackers\n",
        "tracker = cv2.TrackerCSRT_create()\n",
        "success, box = tracker.update(frame)\n",
        "```\n",
        "\n",
        "### 3. Illumination and Contrast Variations:\n",
        "\n",
        "**Problem:** Changes in lighting conditions can affect the visibility of objects.\n",
        "\n",
        "**Solution:** Apply histogram equalization or adjust the contrast to enhance image details.\n",
        "\n",
        "```python\n",
        "# Histogram Equalization\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "equalized_image = cv2.equalizeHist(gray_image)\n",
        "\n",
        "# Contrast Adjustment\n",
        "alpha = 1.5  # contrast control (1.0 means no change)\n",
        "beta = 30    # brightness control\n",
        "adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "```\n",
        "\n",
        "### 4. Varied Object Appearances:\n",
        "\n",
        "**Problem:** Objects may have different appearances due to changes in orientation, scale, or viewpoint.\n",
        "\n",
        "**Solution:** Use feature-based methods for object detection and matching.\n",
        "\n",
        "```python\n",
        "# Example: SIFT (Scale-Invariant Feature Transform)\n",
        "sift = cv2.SIFT_create()\n",
        "keypoints, descriptors = sift.detectAndCompute(image, None)\n",
        "```\n",
        "\n",
        "**Additional Techniques:** Other feature detectors and descriptors include ORB, SURF, and BRISK.\n",
        "\n",
        "### 5. Dynamic Environments:\n",
        "\n",
        "**Problem:** In dynamic environments, the background may change over time.\n",
        "\n",
        "**Solution:** Implement background subtraction techniques for detecting moving objects.\n",
        "\n",
        "```python\n",
        "# Example: Background Subtraction using MOG2\n",
        "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "foreground_mask = bg_subtractor.apply(frame)\n",
        "```\n",
        "\n",
        "These strategies can be combined and adjusted based on the specific challenges in a given real-world scenario. Additionally, machine learning-based approaches, such as deep learning models, can be employed for more complex and adaptive solutions. Always test and fine-tune methods based on the characteristics of the images and challenges encountered in the specific application domain."
      ],
      "metadata": {
        "id": "f7QpvQPH_kYf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkdK8lKP9qD8"
      },
      "outputs": [],
      "source": []
    }
  ]
}