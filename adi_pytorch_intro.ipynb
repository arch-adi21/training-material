{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction to PyTorch**\n",
        "\n",
        "PyTorch is an open-source machine learning library developed by Facebook's AI Research lab (FAIR). It provides a flexible and dynamic computational graph, allowing for easier experimentation and efficient deployment of deep learning models. PyTorch is widely used in both academia and industry due to its simplicity, flexibility, and strong community support.\n",
        "\n",
        "**1. Getting Started with PyTorch**\n",
        "\n",
        "**Installation:**\n",
        "You can install PyTorch using pip or conda, depending on your preference and system configuration.\n",
        "\n",
        "```bash\n",
        "# Using pip\n",
        "pip install torch torchvision\n",
        "\n",
        "# Using conda\n",
        "conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia\n",
        "```\n",
        "\n",
        "**Basic Concepts:**\n",
        "- **Tensors**: Tensors are the fundamental data structures in PyTorch, similar to NumPy arrays but optimized for GPU acceleration.\n",
        "- **Autograd**: PyTorch's automatic differentiation library allows for dynamic computation of gradients.\n",
        "- **Modules and nn**: The `torch.nn` module provides tools for building neural networks, including various layers, loss functions, and optimizers.\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Create a tensor\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "print(x)\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc = torch.nn.Linear(2, 1)  # Fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleNN()\n",
        "```\n",
        "\n",
        "**2. Building Neural Networks**\n",
        "\n",
        "PyTorch provides a flexible way to define neural networks using the `torch.nn.Module` class. You can create custom architectures by defining the layers and implementing the `forward` method.\n",
        "\n",
        "```python\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomCNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc = torch.nn.Linear(32 * 28 * 28, 10)  # 28x28 is the size of input image\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, 32 * 28 * 28)  # Flatten the output\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = CustomCNN()\n",
        "```\n",
        "\n",
        "**3. Training and Evaluation**\n",
        "\n",
        "PyTorch makes it easy to train and evaluate neural networks using built-in functionalities like optimizers and loss functions.\n",
        "\n",
        "```python\n",
        "# Define loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "```\n",
        "\n",
        "**4. Transfer Learning**\n",
        "\n",
        "Transfer learning involves leveraging pre-trained models for tasks different from what they were originally trained on. PyTorch makes it straightforward to perform transfer learning.\n",
        "\n",
        "```python\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load a pre-trained model\n",
        "pretrained_resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze layers\n",
        "for param in pretrained_resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the fully connected layer\n",
        "pretrained_resnet.fc = torch.nn.Linear(pretrained_resnet.fc.in_features, num_classes)\n",
        "\n",
        "# Training with new data\n",
        "```\n",
        "\n",
        "**5. Real-world Datasets**\n",
        "\n",
        "PyTorch provides easy access to popular datasets through the `torchvision.datasets` module, including CIFAR-10, MNIST, and ImageNet.\n",
        "\n",
        "```python\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "```\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "PyTorch is a powerful deep learning framework that provides flexibility and ease of use for both beginners and advanced users. With its dynamic computation graph and extensive collection of tools, PyTorch is suitable for various machine learning tasks, from simple experiments to complex research projects and production deployments. By mastering PyTorch, you can unleash your creativity and build state-of-the-art deep learning models."
      ],
      "metadata": {
        "id": "Y_neegChIr_f"
      }
    }
  ]
}